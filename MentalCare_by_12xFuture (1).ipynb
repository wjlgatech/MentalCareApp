{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Access\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1osMp_Nve0o0TI6OM2f3CIAMxjt2peQ6g?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/wjlgatech/MentalCareApp/blob/master/MentalCare_by_12xFuture.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "xjUCyx-QfBFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Design Docs\n",
        "- [WordAlive -- Reprograming Your Words to Make You fully Alive\n",
        "](https://docs.google.com/document/d/1b85aPSSubMDez0wAIUzGHNLGWAx_KFLe5au9b01Lht0/edit?usp=sharing)\n",
        "\n",
        "- [Hackathon 12XFuture prompts for Depression](https://docs.google.com/document/d/1U_Pp1GFNha3zriA4_xrt6G_nZuGFoQQdYlXy6iIqt10/edit?usp=sharing)"
      ],
      "metadata": {
        "id": "oAESRWfmoeRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "zgWfJ9A9v7i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nHOzIlkwAQv",
        "outputId": "a1738468-6aa5-48a0-f08a-301790f91901"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (3.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.20.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from gradio) (1.22.4)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from gradio) (8.4.0)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.7-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.7/140.7 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.92.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from gradio) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from gradio) (4.5.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.8/dist-packages (from gradio) (1.10.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from gradio) (3.8.4)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.8/dist-packages (from gradio) (2.1.2)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from gradio) (2023.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from gradio) (3.5.3)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.8/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py<3,>=1\n",
            "  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (3.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Collecting starlette<0.26.0,>=0.25.0\n",
            "  Downloading starlette-0.25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->gradio) (4.0.0)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn->gradio) (8.1.3)\n",
            "Collecting anyio<5.0,>=3.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (5.12.0)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->gradio) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0->altair>=4.2.0->gradio) (3.15.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=0caae75598956dcbeaefcb30076b86d9941896801cd7081166444fc517248b5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: rfc3986, pydub, ffmpy, websockets, uc-micro-py, sniffio, python-multipart, pycryptodome, orjson, mdurl, h11, aiofiles, uvicorn, markdown-it-py, linkify-it-py, anyio, starlette, mdit-py-plugins, httpcore, httpx, fastapi, gradio\n",
            "Successfully installed aiofiles-23.1.0 anyio-3.6.2 fastapi-0.92.0 ffmpy-0.3.0 gradio-3.20.0 h11-0.14.0 httpcore-0.16.3 httpx-0.23.3 linkify-it-py-2.0.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.7 pycryptodome-3.17 pydub-0.25.1 python-multipart-0.0.6 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.25.0 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# user info (collected through user profile)\n",
        "name = \"Rose\"\n",
        "gender = \"Female\"\n",
        "age = \"30 to 40\"\n",
        "profession = \"software developer\"\n",
        "marriage = \"single mom\"\n",
        "struggle_ls = [\"depression\", \"unemployment\", \"anxiety\"]"
      ],
      "metadata": {
        "id": "0SzuinTgvpV-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MentalCare: ChatGPT + DALLE + Gradio\n",
        "\n"
      ],
      "metadata": {
        "id": "nRbV4U90zhYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import os\n",
        "import openai\n",
        "import requests\n",
        "import json\n",
        "\n",
        "api_key = \"YOUR-API-KEY\"\n",
        "openai.api_key = api_key #os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "context_prompt = f\"\"\"The following is a conversation between 'Future-You', an AI assistant, and a real person {name}. \n",
        "{name} is a {gender} of {age} years old; {name}'s profession is a {profession}; {name} is {marriage}; {name} is recently struggling with {','.join(struggle_ls)}.\n",
        "The AI assistant 'Future-You' is helpful, creative, clever, and very friendly.\\n\\nFuture-You: I am the Future-You, a conversational AI engine designed and nurtured by You. \n",
        "After 'Future-You' answers the question from the user 'You', following by asking the user one and only one question from one of the following options. \n",
        "Options include:\n",
        "          - Sympathy: Please show a deep understanding of the situation, show deep compassion to comfort and to care for the struggling soul.\n",
        "          - Wording: Please provide 3 to 5 simple, easily visualizable sentences you can speak to yourself, even with a great sense of humor.\n",
        "          - Action:  Please suggest physical exercise, journaling, and volunteering work that shifts the struggling person's perspective, and increases strength, skills, stemma, and symphony.\n",
        "          - Visualization: Please create a mental picture and inner movie in vivid detail of what the wonderful and happy results could look like.\n",
        "          - Emotion: Please recommend song and pure music to comfort, encourage, and inspire the struggling person.',\n",
        "          - Sharing: Please write a blog post about the person overcoming experience and share it with family and friends of the user's choice. Ask the person if there is someone he/she can help.\n",
        "The answer 'Future-You' provide should always include these 4 parts: \n",
        "1) showing sympathy or affirmation, \n",
        "2) providing suggestions, following the Options mentioned above\n",
        "3) providing an explanation on why that suggestions work\n",
        "4) asking the user new question, in order to helping the user to understand the deeper root cause of problem OR strengthen the positive momentum the user has made\n",
        "\n",
        "The language 'Future-You' uses should be easily visualizable, actionable, compassionate and very humorous!\n",
        "\"\"\"\n",
        "\n",
        "# generate image by DALLE\n",
        "import requests\n",
        "def generate_image(prompt):\n",
        "    url = \"https://api.openai.com/v1/images/generations\"\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": f\"Bearer {api_key}\"\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"image-alpha-001\",\n",
        "        \"prompt\": prompt,\n",
        "        \"num_images\": 1,\n",
        "        \"size\": \"512x512\",\n",
        "        \"response_format\": \"url\"\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"data\"][0][\"url\"]\n",
        "\n",
        "# generate a text using the ChatGPT API\n",
        "def generate_text(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-002\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    message = response.choices[0].text.strip()\n",
        "    return message\n",
        "\n",
        "# define a chatbot that either generate image OR text according to input_text\n",
        "def chatbot(input_text):\n",
        "    if \"imag\" in input_text.lower() or \"visualiz\" in input_text.lower() or \"see\" in input_text.lower():\n",
        "        return generate_image(input_text), \"Here's the generated image:\"\n",
        "    else:\n",
        "        return generate_text(input_text), \"\"\n",
        "\n",
        "#prompt_templates = {\"Default ChatGPT\": \"\"}\n",
        "prompt_templates = {\"Future You\": context_prompt}\n",
        "\n",
        "def get_empty_state():\n",
        "    return {\"total_tokens\": 0, \"messages\": []}\n",
        "\n",
        "def download_prompt_templates():\n",
        "    #if url == \"\":\n",
        "    # credits: https://github.com/f/awesome-chatgpt-prompts\n",
        "    url = \"https://raw.githubusercontent.com/f/awesome-chatgpt-prompts/main/prompts.csv\" #\"https://raw.githubusercontent.com/wjlgatech/WordsAliveApp/master/data/prompts.csv\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    for line in response.text.splitlines()[1:]:\n",
        "        act, prompt = line.split('\",\"')\n",
        "        prompt_templates[act.replace('\"', '')] = prompt.replace('\"', '')\n",
        "\n",
        "    choices = list(prompt_templates.keys())\n",
        "    return gr.update(value=choices[0], choices=choices)\n",
        "\n",
        "def on_token_change(user_token):\n",
        "    openai.api_key = user_token or os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "def on_prompt_template_change(prompt_template):\n",
        "    if not isinstance(prompt_template, str): return\n",
        "    return prompt_templates[prompt_template]\n",
        "\n",
        "def submit_message(user_token, prompt, prompt_template, temperature, max_tokens, state):\n",
        "\n",
        "    history = state['messages']\n",
        "\n",
        "    if not prompt:\n",
        "        return gr.update(value='', visible=state['total_tokens'] < 1_000), [(history[i]['content'], history[i+1]['content']) for i in range(0, len(history)-1, 2)], f\"Total tokens used: {state['total_tokens']} / 3000\", state\n",
        "    \n",
        "    prompt_template = prompt_templates[prompt_template]\n",
        "\n",
        "    system_prompt = []\n",
        "    if prompt_template:\n",
        "        system_prompt = [{ \"role\": \"system\", \"content\": prompt_template }]\n",
        "\n",
        "    prompt_msg = { \"role\": \"user\", \"content\": prompt }\n",
        "    \n",
        "    try:\n",
        "        completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=system_prompt + history + [prompt_msg], temperature=temperature, max_tokens=max_tokens)\n",
        "\n",
        "        history.append(prompt_msg)\n",
        "        history.append(completion.choices[0].message.to_dict())\n",
        "\n",
        "        state['total_tokens'] += completion['usage']['total_tokens']\n",
        "    \n",
        "    except Exception as e:\n",
        "        history.append(prompt_msg)\n",
        "        history.append({\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"Error: {e}\"\n",
        "        })\n",
        "\n",
        "    total_tokens_used_msg = f\"Total tokens used: {state['total_tokens']} / 3000\" if not user_token else \"\"\n",
        "    chat_messages = [(history[i]['content'], history[i+1]['content']) for i in range(0, len(history)-1, 2)]\n",
        "    input_visibility = user_token or state['total_tokens'] < 3000\n",
        "\n",
        "    return gr.update(value='', visible=input_visibility), chat_messages, total_tokens_used_msg, state\n",
        "\n",
        "def clear_conversation():\n",
        "    return gr.update(value=None, visible=True), None, \"\", get_empty_state()\n",
        "\n",
        "css = \"\"\"\n",
        "      #col-container {max-width: 80%; margin-left: auto; margin-right: auto;}\n",
        "      #chatbox {min-height: 400px;}\n",
        "      #header {text-align: center;}\n",
        "      #prompt_template_preview {padding: 1em; border-width: 1px; border-style: solid; border-color: #e0e0e0; border-radius: 4px;}\n",
        "      #total_tokens_str {text-align: right; font-size: 0.8em; color: #666; height: 1em;}\n",
        "      #label {font-size: 0.8em; padding: 0.5em; margin: 0;}\n",
        "      \"\"\"\n",
        "\n",
        "### chatbot_interface1\n",
        "chatbot_interface1 = gr.Interface(\n",
        "    fn=chatbot,\n",
        "    inputs=gr.inputs.Textbox(label=\"Input\"),\n",
        "    outputs=[\n",
        "        gr.outputs.Image(label=\"Generated Image\", type='pil'),\n",
        "        gr.outputs.Textbox(label=\"Output\")\n",
        "    ],\n",
        "    title=\"Generating Mental Image\",\n",
        "    description=\"\",\n",
        "    examples=[[\"Hello\", \"Hi!\"], [\"Can you show me the visualization?\", \"Here's the generated image:\"]]\n",
        ")\n",
        "\n",
        "chatbot_interface1.launch()\n",
        "\n",
        "### chatbot_interface2\n",
        "\n",
        "\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    \n",
        "    state = gr.State(get_empty_state())\n",
        "\n",
        "\n",
        "    with gr.Column(elem_id=\"col-container\"):\n",
        "        gr.Markdown(\"\"\"## Mental Care\n",
        "                    AI Psychological Assistant<br>\n",
        "                    \"\"\",\n",
        "                    elem_id=\"header\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                chatbot = gr.Chatbot(elem_id=\"chatbox\")\n",
        "                input_message = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\", visible=True).style(container=False)\n",
        "                total_tokens_str = gr.Markdown(elem_id=\"total_tokens_str\")\n",
        "                btn_clear_conversation = gr.Button(\"🔃 Start New Conversation\")\n",
        "            with gr.Column():\n",
        "                prompt_template = gr.Dropdown(label=\"Select a template for the chatbot:\", choices=list(prompt_templates.keys()))\n",
        "                prompt_template_preview = gr.Markdown(elem_id=\"prompt_template_preview\")\n",
        "                gr.Markdown(\"Enter your own OpenAI API Key to remove the 3000 token limit. You can get it [here](https://platform.openai.com/account/api-keys).\", elem_id=\"label\")\n",
        "                user_token = gr.Textbox(placeholder=\"OpenAI API Key\", type=\"password\", show_label=False)\n",
        "                with gr.Accordion(\"Advanced parameters\", open=False):\n",
        "                    temperature = gr.Slider(minimum=0, maximum=2.0, value=0.7, step=0.1, interactive=True, label=\"Temperature (higher = more creative/chaotic)\")\n",
        "                    max_tokens = gr.Slider(minimum=100, maximum=4096, value=1000, step=1, interactive=True, label=\"Max tokens per response\")\n",
        "\n",
        "    gr.HTML('''<br><br><br><center><a href=\"https://huggingface.co/spaces/anzorq/chatgpt-demo?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>You can duplicate this Space.<br>\n",
        "            Don't forget to set your own <a href=\"https://platform.openai.com/account/api-keys\">OpenAI API Key</a> environment variable in Settings.</center>''')\n",
        "\n",
        "    input_message.submit(submit_message, [user_token, input_message, prompt_template, temperature, max_tokens, state], [input_message, chatbot, total_tokens_str, state])\n",
        "\n",
        "    btn_clear_conversation.click(clear_conversation, [], [input_message, chatbot, total_tokens_str, state])\n",
        "    prompt_template.change(on_prompt_template_change, inputs=[prompt_template], outputs=[prompt_template_preview])\n",
        "    user_token.change(on_token_change, inputs=[user_token], outputs=[])\n",
        "\n",
        "    \n",
        "    demo.load(download_prompt_templates, inputs=None, outputs=[prompt_template])\n",
        "\n",
        "\n",
        "demo.launch(debug=True, height='800px')\n",
        "\n"
      ],
      "metadata": {
        "id": "yFq58051zpGw",
        "outputId": "00062fa7-28fa-4f2e-eaf1-4f5e1d70c6ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/outputs.py:43: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", \"800px\", false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObWHZ-Tqf4TU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}